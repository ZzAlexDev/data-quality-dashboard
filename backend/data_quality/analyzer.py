"""
analyzer.py - –†–µ–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä CSV —Ñ–∞–π–ª–æ–≤ —Å pandas
"""

import pandas as pd
import numpy as np
from django.core.files.storage import default_storage

class CSVAnalyzer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ CSV —Ñ–∞–π–ª–æ–≤.
    –ó–∞–º–µ–Ω—è–µ—Ç —Å—Ç–∞—Ä—É—é –∏–º–∏—Ç–∞—Ü–∏—é _simulate_analysis.
    """
    
    def __init__(self, dataset):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.
        
        Args:
            dataset: –û–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏ Dataset
        """
        self.dataset = dataset
        self.file_path = dataset.csv_file.path
        self.df = None
        
    def analyze(self):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞.
        
        Returns:
            bool: True –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–µ–Ω
        """
        print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {self.file_path}")
        
        try:
            # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º CSV
            self._load_csv()
            
            if self.df is None:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª")
            
            # 2. –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏
            missing_results = self._check_missing_values()
            duplicates_results = self._check_duplicates()
            statistics_results = self._calculate_statistics()
            
            # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self._save_results(missing_results, duplicates_results, statistics_results)
            
            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω –¥–ª—è {self.dataset.name}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
            raise
    
    def _load_csv(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Ñ–∞–π–ª –≤ DataFrame pandas."""
        try:
            self.df = pd.read_csv(self.file_path, encoding='utf-8')
            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(self.df)} —Å—Ç—Ä–æ–∫, {len(self.df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
        except UnicodeDecodeError:
            try:
                self.df = pd.read_csv(self.file_path, encoding='cp1251')
                print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π cp1251")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
                raise
    
    def _check_missing_values(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è."""
        print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è...")
        
        total_cells = self.df.size
        missing_cells = self.df.isna().sum().sum()
        missing_percentage = (missing_cells / total_cells) * 100 if total_cells > 0 else 0
        
        # –î–µ—Ç–∞–ª–∏ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º
        columns_with_missing = {}
        for column in self.df.columns:
            missing_count = self.df[column].isna().sum()
            if missing_count > 0:
                columns_with_missing[column] = int(missing_count)
        
        return {
            'total_rows': len(self.df),
            'total_columns': len(self.df.columns),
            'total_cells': int(total_cells),
            'missing_cells': int(missing_cells),
            'missing_percentage': round(missing_percentage, 2),
            'columns_with_missing': columns_with_missing
        }
    
    def _check_duplicates(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫."""
        print("‚ôªÔ∏è –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫...")
        
        total_rows = len(self.df)
        duplicate_rows = self.df.duplicated().sum()
        duplicate_percentage = (duplicate_rows / total_rows) * 100 if total_rows > 0 else 0
        
        return {
            'total_rows': total_rows,
            'duplicate_rows': int(duplicate_rows),
            'duplicate_percentage': round(duplicate_percentage, 2)
        }
    
    def _calculate_statistics(self):
        """–°—á–∏—Ç–∞–µ—Ç –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
        print("üìä –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É...")
        
        numeric_stats = {}
        text_stats = {}
        
        for column in self.df.columns:
            # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
            if pd.api.types.is_numeric_dtype(self.df[column]):
                numeric_stats[column] = {
                    'min': float(self.df[column].min()) if not self.df[column].isna().all() else None,
                    'max': float(self.df[column].max()) if not self.df[column].isna().all() else None,
                    'mean': float(self.df[column].mean()) if not self.df[column].isna().all() else None,
                    'std': float(self.df[column].std()) if not self.df[column].isna().all() else None,
                    'missing': int(self.df[column].isna().sum())
                }
            
            # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
            elif pd.api.types.is_string_dtype(self.df[column]):
                text_stats[column] = {
                    'unique_values': int(self.df[column].nunique()),
                    'most_common': str(self.df[column].mode().iloc[0]) if not self.df[column].mode().empty else None,
                    'missing': int(self.df[column].isna().sum())
                }
        
        return {
            'numeric_columns': numeric_stats,
            'text_columns': text_stats,
            'total_columns': len(self.df.columns)
        }
    
    def _save_results(self, missing_results, duplicates_results, statistics_results):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö."""
        from .models import DataCheck, Report
        
        # –£–î–ê–õ–Ø–ï–ú —Å—Ç–∞—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        DataCheck.objects.filter(dataset=self.dataset).delete()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        DataCheck.objects.create(
            dataset=self.dataset,
            check_type='missing',
            result_json=missing_results
        )
        
        DataCheck.objects.create(
            dataset=self.dataset,
            check_type='duplicates',
            result_json=duplicates_results
        )
        
        DataCheck.objects.create(
            dataset=self.dataset,
            check_type='statistics',
            result_json=statistics_results
        )
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        issues_count = missing_results['missing_cells'] + duplicates_results['duplicate_rows']
        
        summary = f"""
üìä –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Ñ–∞–π–ª—É {self.dataset.name}

üìà –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:
- –°—Ç—Ä–æ–∫: {missing_results['total_rows']}
- –°—Ç–æ–ª–±—Ü–æ–≤: {missing_results['total_columns']}
- –Ø—á–µ–µ–∫: {missing_results['total_cells']}

‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö:
- –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {missing_results['missing_cells']} ({missing_results['missing_percentage']}%)
- –î—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å—Ç—Ä–æ–∫: {duplicates_results['duplicate_rows']} ({duplicates_results['duplicate_percentage']}%)

üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
{self._generate_recommendations(missing_results, duplicates_results)}
        """
        
        # –û–ë–ù–û–í–õ–Ø–ï–ú –∏–ª–∏ –°–û–ó–î–ê–ï–ú –æ—Ç—á–µ—Ç
        report, created = Report.objects.update_or_create(
            dataset=self.dataset,
            defaults={
                'summary': summary,
                'issues_count': int(issues_count)
            }
        )
        
        if created:
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –æ—Ç—á–µ—Ç –¥–ª—è {self.dataset.name}")
        else:
            print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ—Ç—á–µ—Ç –¥–ª—è {self.dataset.name}")
            
    def _generate_recommendations(self, missing_results, duplicates_results):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        recommendations = []
        
        if missing_results['missing_cells'] > 0:
            recommendations.append("‚Ä¢ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ:")
            recommendations.append("  - –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏–º–∏/–º–æ–¥–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏")
            recommendations.append("  - –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ (–µ—Å–ª–∏ –∏—Ö –Ω–µ–º–Ω–æ–≥–æ)")
        
        if duplicates_results['duplicate_rows'] > 0:
            recommendations.append("‚Ä¢ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–¥–∞–ª–∏—Ç—å.")
        
        if not recommendations:
            recommendations.append("‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Ä–æ—à–µ–µ! –°–µ—Ä—å–µ–∑–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")
        
        return "\n".join(recommendations)